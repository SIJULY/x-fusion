# services/jobs.py
import asyncio
import time
import requests
import random
import logging
from collections import Counter
from apscheduler.schedulers.asyncio import AsyncIOScheduler

from core.state import (
    SERVERS_CACHE, NODES_DATA, PROBE_DATA_CACHE,
    ADMIN_CONFIG, DASHBOARD_REFS
)
from core.storage import save_admin_config, save_nodes_cache, save_servers
from services.xui_api import fetch_inbounds_safe
from services.geoip import detect_country_group, job_check_geo_ip

logger = logging.getLogger("Services.Jobs")

# ================= TG æŠ¥è­¦ =================
ALERT_CACHE = {}
FAILURE_COUNTS = {}


async def send_telegram_message(text):
    token = ADMIN_CONFIG.get('tg_bot_token')
    chat_id = ADMIN_CONFIG.get('tg_chat_id')
    if not token or not chat_id: return

    url = f"https://api.telegram.org/bot{token}/sendMessage"
    try:
        requests.post(url, json={"chat_id": chat_id, "text": text, "parse_mode": "Markdown"}, timeout=5)
    except:
        pass


# ================= çŠ¶æ€ç›‘æ§ä»»åŠ¡ =================
async def get_server_status(server_conf):
    """è·å–å•å°æœåŠ¡å™¨çŠ¶æ€ (ä¼˜å…ˆç¼“å­˜)"""
    url = server_conf['url']
    # æ¢é’ˆæˆ–ç¼“å­˜ä¼˜å…ˆ
    if server_conf.get('probe_installed') or url in PROBE_DATA_CACHE:
        cache = PROBE_DATA_CACHE.get(url)
        if cache and (time.time() - cache.get('last_updated', 0) < 15):
            return cache
    return {'status': 'offline', 'msg': 'æœªå®‰è£…æ¢é’ˆ'}


async def job_monitor_status():
    """
    æ¯2åˆ†é’Ÿæ‰§è¡Œï¼šæ£€æŸ¥æ¢é’ˆåœ¨çº¿çŠ¶æ€å¹¶æŠ¥è­¦
    """
    sema = asyncio.Semaphore(50)
    current_time = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())

    async def _check(srv):
        if not srv.get('probe_installed'): return

        async with sema:
            res = await get_server_status(srv)
            is_online = (res.get('status') == 'online')
            url = srv['url']
            name = srv.get('name', 'Unknown')

            if is_online:
                FAILURE_COUNTS[url] = 0
                if ALERT_CACHE.get(url) == 'offline':
                    asyncio.create_task(send_telegram_message(f"ğŸŸ¢ **æ¢å¤**: {name} å·²ä¸Šçº¿\nğŸ•’ {current_time}"))
                    ALERT_CACHE[url] = 'online'
            else:
                FAILURE_COUNTS[url] = FAILURE_COUNTS.get(url, 0) + 1
                if FAILURE_COUNTS[url] >= 3 and ALERT_CACHE.get(url) != 'offline':
                    asyncio.create_task(send_telegram_message(f"ğŸ”´ **æŠ¥è­¦**: {name} ç¦»çº¿\nğŸ•’ {current_time}"))
                    ALERT_CACHE[url] = 'offline'

    tasks = [_check(s) for s in SERVERS_CACHE]
    await asyncio.gather(*tasks)


# ================= æµé‡åŒæ­¥ä»»åŠ¡ (ä»… API æ¨¡å¼) =================
async def job_sync_all_traffic():
    """
    æ¯24å°æ—¶æ‰§è¡Œï¼šè½®è¯¢ API æœºå™¨æ›´æ–°æµé‡
    """
    logger.info("ğŸ•’ [åŒæ­¥ä»»åŠ¡] æ£€æŸ¥æµé‡åŒæ­¥è¿›åº¦...")
    start_ts = ADMIN_CONFIG.get('sync_job_start', 0)
    current_idx = ADMIN_CONFIG.get('sync_job_index', 0)
    now = time.time()

    # é‡ç½®é€»è¾‘
    if (now - start_ts > 86400) or start_ts == 0 or current_idx >= len(SERVERS_CACHE):
        start_ts = now;
        current_idx = 0
        ADMIN_CONFIG.update({'sync_job_start': start_ts, 'sync_job_index': 0})
        await save_admin_config()

    i = current_idx
    while i < len(SERVERS_CACHE):
        server = SERVERS_CACHE[i]

        # è·³è¿‡æ¢é’ˆæœºå™¨ (å®ƒä»¬ä¼šè‡ªåŠ¨æ¨é€)
        if server.get('probe_installed'):
            i += 1
            continue

        try:
            await fetch_inbounds_safe(server, force_refresh=True)
            # åŠ¨æ€ä¼‘çœ é˜²å°
            await asyncio.sleep(random.uniform(1, 2))
        except:
            pass

        i += 1
        # ä¿å­˜è¿›åº¦
        if i % 5 == 0:
            ADMIN_CONFIG['sync_job_index'] = i
            await save_admin_config()

    await save_nodes_cache()
    logger.info("âœ… [åŒæ­¥ä»»åŠ¡] æœ¬è½®å®Œæˆ")


# ================= ä»ªè¡¨ç›˜æ•°æ®è®¡ç®— (æ ¸å¿ƒ) =================
def calculate_dashboard_data():
    """è®¡ç®—ä»ªè¡¨ç›˜æ‰€éœ€çš„ç»Ÿè®¡æ•°æ® (Server, Nodes, Traffic, Charts)"""
    try:
        total_srv = len(SERVERS_CACHE)
        online_srv = 0
        total_nodes = 0
        total_traffic = 0

        traffic_map = {}
        country_cnt = Counter()
        now_ts = time.time()

        for s in SERVERS_CACHE:
            nodes = NODES_DATA.get(s['url'], []) or []
            probe = PROBE_DATA_CACHE.get(s['url'])
            custom = s.get('custom_nodes', [])

            # 1. åŒºåŸŸç»Ÿè®¡
            c_name = detect_country_group(s.get('name', ''), s) or "ğŸ³ï¸ æœªçŸ¥"
            country_cnt[c_name] += 1

            # 2. æµé‡ç»Ÿè®¡ (ä¼˜å…ˆæ¢é’ˆ)
            s_traffic = 0
            if s.get('probe_installed') and probe:
                s_traffic = probe.get('net_total_in', 0) + probe.get('net_total_out', 0)
            elif nodes:
                s_traffic = sum(n.get('up', 0) + n.get('down', 0) for n in nodes)

            total_traffic += s_traffic
            traffic_map[s.get('name')] = s_traffic

            # 3. åœ¨çº¿åˆ¤å®š
            is_on = False
            if probe and (now_ts - probe.get('last_updated', 0) < 60):
                is_on = True
            elif nodes or s.get('_status') == 'online':
                is_on = True

            if is_on: online_srv += 1
            total_nodes += len(nodes) + len(custom)

        # æ„å»ºå›¾è¡¨æ•°æ®
        top_traffic = sorted(traffic_map.items(), key=lambda x: x[1], reverse=True)[:15]

        pie_data = []
        if len(country_cnt) > 5:
            top_5 = country_cnt.most_common(5)
            others = sum(country_cnt.values()) - sum(x[1] for x in top_5)
            pie_data = [{'name': f"{k} ({v})", 'value': v} for k, v in top_5]
            if others > 0: pie_data.append({'name': f"ğŸ³ï¸ å…¶ä»– ({others})", 'value': others})
        else:
            pie_data = [{'name': f"{k} ({v})", 'value': v} for k, v in country_cnt.items()]

        return {
            "servers": f"{online_srv}/{total_srv}",
            "nodes": str(total_nodes),
            "traffic": f"{total_traffic / 1024 ** 3:.2f} GB",
            "subs": str(len(ADMIN_CONFIG.get('subs', []))),  # æš‚ç”¨
            "bar_chart": {"names": [x[0] for x in top_traffic],
                          "values": [round(x[1] / 1024 ** 3, 2) for x in top_traffic]},
            "pie_chart": pie_data
        }
    except:
        return None


async def refresh_dashboard_ui_trigger():
    """è§¦å‘å‰ç«¯ UI åˆ·æ–° (é€šè¿‡ State ä¸­çš„å¼•ç”¨)"""
    data = calculate_dashboard_data()
    if not data: return

    # ç®€å•çš„æ–‡æœ¬æ›´æ–°
    if DASHBOARD_REFS['servers']: DASHBOARD_REFS['servers'].set_text(data['servers'])
    if DASHBOARD_REFS['nodes']: DASHBOARD_REFS['nodes'].set_text(data['nodes'])
    if DASHBOARD_REFS['traffic']: DASHBOARD_REFS['traffic'].set_text(data['traffic'])

    # å›¾è¡¨æ›´æ–°éœ€åœ¨ UI çº¿ç¨‹ä¸­åšï¼Œè¿™é‡Œä»…æ›´æ–°æ•°æ®æº
    if DASHBOARD_REFS['bar_chart']:
        DASHBOARD_REFS['bar_chart'].options['xAxis']['data'] = data['bar_chart']['names']
        DASHBOARD_REFS['bar_chart'].options['series'][0]['data'] = data['bar_chart']['values']
        DASHBOARD_REFS['bar_chart'].update()


# ================= è°ƒåº¦å™¨å¯åŠ¨ =================
scheduler = AsyncIOScheduler()


async def start_scheduler():
    from services.ping import PROCESS_POOL
    # æ­¤å¤„å‡è®¾ PROCESS_POOL å·²åœ¨ main.py åˆå§‹åŒ–

    scheduler.add_job(job_sync_all_traffic, 'interval', hours=24, id='traffic_sync')
    scheduler.add_job(job_monitor_status, 'interval', seconds=120, id='status_monitor')
    scheduler.add_job(job_check_geo_ip, 'interval', hours=1, id='geoip_check')

    scheduler.start()
    logger.info("ğŸ•’ è°ƒåº¦ä»»åŠ¡å·²å¯åŠ¨")

    # å¼€æœºç«‹å³è¿è¡Œä¸€æ¬¡
    asyncio.create_task(job_sync_all_traffic())