# logic.py
import json
import os
import asyncio
import time
import logging
import datetime
import zipfile
import io
import shutil
import socket
import re
import requests
from concurrent.futures import ThreadPoolExecutor

import config
import state
import utils

logger = logging.getLogger("XUI_Manager")

# ================= 0. é¡¶å±‚åŒæ­¥å‡½æ•° (ç”¨äºå¤šè¿›ç¨‹è°ƒç”¨) =================

def _save_json_sync(file_path, data):
    """åŒæ­¥å†™å…¥ JSON æ–‡ä»¶"""
    parent = os.path.dirname(file_path)
    if not os.path.exists(parent):
        os.makedirs(parent)
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=2, ensure_ascii=False)
    return True

def _save_nodes_sync(file_path, data):
    """åŒæ­¥å†™å…¥èŠ‚ç‚¹ç¼“å­˜ (ç´§å‡‘æ ¼å¼)"""
    parent = os.path.dirname(file_path)
    if not os.path.exists(parent):
        os.makedirs(parent)
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False)
    return True

def _zip_backup_sync(data_dir, zip_filename):
    """åŒæ­¥åˆ›å»ºå‹ç¼©åŒ…"""
    with zipfile.ZipFile(zip_filename, 'w') as zf:
        if os.path.exists(data_dir):
            for root, _, files in os.walk(data_dir):
                for file in files:
                    file_path = os.path.join(root, file)
                    arcname = os.path.relpath(file_path, data_dir)
                    zf.write(file_path, arcname)
    return zip_filename

def _unzip_backup_sync(content_bytes, data_dir):
    """åŒæ­¥è§£å‹æ¢å¤"""
    try:
        with zipfile.ZipFile(io.BytesIO(content_bytes)) as zf:
            if os.path.exists(data_dir):
                shutil.rmtree(data_dir)
            os.makedirs(data_dir)
            zf.extractall(data_dir)
        return True
    except:
        return False

# ================= 1. æ•°æ®åˆå§‹åŒ–ä¸ä¿å­˜ =================

def init_data():
    """åˆå§‹åŒ–æ•°æ®ç›®å½•å’ŒåŠ è½½ç¼“å­˜"""
    if not os.path.exists(config.DATA_DIR):
        os.makedirs(config.DATA_DIR)
        logger.info(f"åˆ›å»ºæ•°æ®ç›®å½•: {config.DATA_DIR}")

    # 1. åŠ è½½æœåŠ¡å™¨åˆ—è¡¨
    if os.path.exists(config.CONFIG_FILE):
        try:
            with open(config.CONFIG_FILE, 'r', encoding='utf-8') as f:
                state.SERVERS_CACHE = json.load(f)
            logger.info(f"âœ… åŠ è½½æœåŠ¡å™¨: {len(state.SERVERS_CACHE)} å°")
        except Exception as e:
            logger.error(f"åŠ è½½æœåŠ¡å™¨é…ç½®å¤±è´¥: {e}")
            state.SERVERS_CACHE = []
    else:
        logger.warning(f"âš ï¸ æœªæ‰¾åˆ°æœåŠ¡å™¨é…ç½®æ–‡ä»¶: {config.CONFIG_FILE}")

    # 2. åŠ è½½èŠ‚ç‚¹ç¼“å­˜
    if os.path.exists(config.NODES_CACHE_FILE):
        try:
            with open(config.NODES_CACHE_FILE, 'r', encoding='utf-8') as f:
                state.NODES_DATA = json.load(f)
            total_nodes = sum(len(nodes) for nodes in state.NODES_DATA.values())
            logger.info(f"âœ… åŠ è½½ç¼“å­˜èŠ‚ç‚¹: {total_nodes} ä¸ª")
        except Exception as e:
            logger.error(f"åŠ è½½èŠ‚ç‚¹ç¼“å­˜å¤±è´¥: {e}")

    # 3. åŠ è½½è®¢é˜…
    if os.path.exists(config.SUBS_FILE):
        try:
            with open(config.SUBS_FILE, 'r', encoding='utf-8') as f:
                state.SUBS_CACHE = json.load(f)
            logger.info(f"âœ… åŠ è½½è®¢é˜…: {len(state.SUBS_CACHE)} ä¸ª")
        except:
            pass

    # 4. åŠ è½½ç®¡ç†å‘˜é…ç½®
    if os.path.exists(config.ADMIN_CONFIG_FILE):
        try:
            with open(config.ADMIN_CONFIG_FILE, 'r', encoding='utf-8') as f:
                saved_conf = json.load(f)
                state.ADMIN_CONFIG.update(saved_conf)
        except:
            pass

async def save_servers():
    try:
        await run_in_bg_executor(_save_json_sync, config.CONFIG_FILE, state.SERVERS_CACHE)
    except Exception as e:
        logger.error(f"ä¿å­˜æœåŠ¡å™¨å¤±è´¥: {e}")

async def save_subs():
    try:
        await run_in_bg_executor(_save_json_sync, config.SUBS_FILE, state.SUBS_CACHE)
    except Exception as e:
        logger.error(f"ä¿å­˜è®¢é˜…å¤±è´¥: {e}")

async def save_nodes_cache():
    try:
        await run_in_bg_executor(_save_nodes_sync, config.NODES_CACHE_FILE, state.NODES_DATA)
    except Exception as e:
        logger.error(f"ä¿å­˜èŠ‚ç‚¹ç¼“å­˜å¤±è´¥: {e}")

async def save_admin_config():
    try:
        await run_in_bg_executor(_save_json_sync, config.ADMIN_CONFIG_FILE, state.ADMIN_CONFIG)
    except:
        pass

# ================= 2. æ ¸å¿ƒä¸šåŠ¡é€»è¾‘ (Dashboard & Maps) =================

def calculate_dashboard_data():
    """è®¡ç®—ä»ªè¡¨ç›˜ç»Ÿè®¡æ•°æ®"""
    try:
        total_servers = len(state.SERVERS_CACHE)
        online_servers = len([s for s in state.SERVERS_CACHE if s.get('_status') == 'online'])
        total_nodes = 0
        total_up = 0
        total_down = 0
        traffic_rank = []

        for srv in state.SERVERS_CACHE:
            url = srv.get('url')
            api_nodes = state.NODES_DATA.get(url, []) or []
            custom_nodes = srv.get('custom_nodes', []) or []
            probe_data = state.PROBE_DATA_CACHE.get(url)

            srv_traffic = 0
            use_probe_traffic = False

            # ä¼˜å…ˆä½¿ç”¨æ¢é’ˆæµé‡
            if srv.get('probe_installed') and probe_data:
                t_in = probe_data.get('net_total_in', 0)
                t_out = probe_data.get('net_total_out', 0)
                if t_in > 0 or t_out > 0:
                    srv_traffic = t_in + t_out
                    use_probe_traffic = True
            
            # å¦åˆ™ç»Ÿè®¡èŠ‚ç‚¹æµé‡
            if not use_probe_traffic:
                for n in api_nodes:
                    srv_traffic += int(n.get('up', 0)) + int(n.get('down', 0))

            total_nodes += len(api_nodes) + len(custom_nodes)
            
            if srv_traffic > 0:
                traffic_rank.append({
                    'name': srv.get('name', 'Unknown'),
                    'value': round(srv_traffic / 1024**3, 2)
                })
            
            # ç®€å•ç´¯åŠ æ€»æµé‡ç”¨äºæ˜¾ç¤º
            if use_probe_traffic:
                total_up += probe_data.get('net_total_out', 0)
                total_down += probe_data.get('net_total_in', 0)
            else:
                for n in api_nodes:
                    total_up += int(n.get('up', 0))
                    total_down += int(n.get('down', 0))

        traffic_rank.sort(key=lambda x: x['value'], reverse=True)
        top_10 = traffic_rank[:10]
        
        bar_chart_data = {'names': [x['name'] for x in top_10], 'values': [x['value'] for x in top_10]}

        from collections import Counter
        region_cnt = Counter()
        for s in state.SERVERS_CACHE:
            group = detect_country_group(s.get('name', ''), s)
            region_cnt[group] += 1
        
        pie_data = []
        most_common = region_cnt.most_common(5)
        for k, v in most_common: pie_data.append({'name': f"{k} ({v})", 'value': v})
        others = sum(region_cnt.values()) - sum(x[1] for x in most_common)
        if others > 0: pie_data.append({'name': f"ğŸ³ï¸ å…¶ä»– ({others})", 'value': others})

        return {
            "servers": f"{online_servers} / {total_servers}",
            "nodes": str(total_nodes),
            "traffic": utils.format_bytes(total_up + total_down),
            "subs": str(len(state.SUBS_CACHE)),
            "bar_chart": bar_chart_data,
            "pie_chart": pie_data
        }
    except Exception as e:
        logger.error(f"ä»ªè¡¨ç›˜æ•°æ®è®¡ç®—é”™è¯¯: {e}")
        return None

def detect_country_group(name, server_obj=None):
    if server_obj and server_obj.get('group') and server_obj['group'] not in ['é»˜è®¤åˆ†ç»„', 'è‡ªåŠ¨æ³¨å†Œ', 'æœªåˆ†ç»„']:
        return server_obj['group']
    for flag, country in config.AUTO_COUNTRY_MAP.items():
        if flag in name: return country
    name_lower = name.lower()
    for key, country in config.AUTO_COUNTRY_MAP.items():
        if len(key) > 2 and key.lower() in name_lower: return country
    return "ğŸ³ï¸ å…¶ä»–åœ°åŒº"

def prepare_map_data():
    """å‡†å¤‡åœ°å›¾å’ŒåŒºåŸŸç»Ÿè®¡æ•°æ®"""
    try:
        city_points_map = {}
        flag_points_map = {}
        unique_deployed_countries = set()
        region_stats = {}
        active_regions_for_highlight = set()
        
        # ç®€åŒ–ç‰ˆæ˜ å°„é€»è¾‘ï¼Œå®é™…å¯æ‰©å±•
        country_centroids = config.COUNTRY_CENTROIDS.copy()
        
        snapshot = list(state.SERVERS_CACHE)
        now_ts = time.time()
        temp_stats = {}

        for s in snapshot:
            s_name = s.get('name', '')
            # å°è¯•æå–å›½æ——
            flag_icon = "ğŸ“"
            try:
                g = detect_country_group(s_name, s)
                if g and " " in g: flag_icon = g.split(" ")[0]
            except: pass

            # åæ ‡
            lat, lon = s.get('lat'), s.get('lon')
            if not lat:
                c = utils.get_coords_from_name(s_name)
                if c: lat, lon = c[0], c[1]
            
            if lat and lon:
                city_points_map[f"{lat},{lon}"] = {'name': s_name, 'value': [lon, lat]}
                # ç»Ÿè®¡
                c_name = detect_country_group(s_name, s)
                if c_name not in temp_stats:
                     temp_stats[c_name] = {'flag': flag_icon, 'cn': c_name, 'total': 0, 'online': 0, 'servers': []}
                
                rs = temp_stats[c_name]
                rs['total'] += 1
                
                # åœ¨çº¿åˆ¤æ–­
                is_on = False
                probe = state.PROBE_DATA_CACHE.get(s['url'])
                if probe and (now_ts - probe.get('last_updated', 0) < 20): is_on = True
                elif s.get('_status') == 'online': is_on = True
                
                if is_on: rs['online'] += 1
                rs['servers'].append({'name': s_name, 'status': 'online' if is_on else 'offline'})
                
                # è®°å½•é«˜äº®åŒºåŸŸ (ç®€å•å¤„ç†ï¼Œå‡è®¾ c_name åŒ…å«è‹±æ–‡æˆ–èƒ½åœ¨ MAP_NAME_ALIASES æ‰¾åˆ°)
                # è¿™é‡Œä¸ºäº†ç®€åŒ–ï¼Œç›´æ¥å°è¯•åŒ¹é… config.MATCH_MAP
                for k, v in config.MATCH_MAP.items():
                    if k in flag_icon: active_regions_for_highlight.add(v)

        return (
            json.dumps({'cities': list(city_points_map.values()), 'flags': [], 'regions': list(active_regions_for_highlight)}, ensure_ascii=False),
            [], # pie data handled in calculate_dashboard
            len(temp_stats),
            json.dumps(temp_stats, ensure_ascii=False),
            json.dumps(country_centroids, ensure_ascii=False)
        )
    except Exception as e:
        logger.error(f"Map data error: {e}")
        return ("{}", [], 0, "{}", "{}")

async def generate_smart_name(server_conf):
    """è‡ªåŠ¨ç”Ÿæˆåç§°"""
    url = server_conf.get('url', '')
    host = server_conf.get('ssh_host')
    if not host and url: host = url.replace('http://', '').replace('https://', '').split(':')[0]
    
    if not host: return "Server"
    
    flag = await run_in_bg_executor(utils.get_flag_from_ip, host)
    # å°è¯•åæŸ¥åŒºåŸŸå
    country = "Unknown"
    for f, c in config.AUTO_COUNTRY_MAP.items():
        if f == flag: country = c.split(' ')[1] if ' ' in c else c; break
    
    return f"{flag} {country}"

# ================= 3. ä»»åŠ¡è°ƒåº¦ä¸åå°æ‰§è¡Œ =================

async def run_in_bg_executor(func, *args):
    loop = asyncio.get_running_loop()
    if state.PROCESS_POOL is None:
        return await loop.run_in_executor(None, func, *args)
    return await loop.run_in_executor(state.PROCESS_POOL, func, *args)

async def get_server_status(server_conf):
    """è·å–å•å°æœåŠ¡å™¨çŠ¶æ€ (ä¼˜å…ˆæ¢é’ˆï¼Œå…¶æ¬¡ API)"""
    url = server_conf.get('url')
    
    # 1. ä¼˜å…ˆè¯»å–æ¢é’ˆç¼“å­˜
    if server_conf.get('probe_installed') or url in state.PROBE_DATA_CACHE:
        cache = state.PROBE_DATA_CACHE.get(url)
        if cache:
            if time.time() - cache.get('last_updated', 0) < 20: # ä¸¥æ ¼ä¸€ç‚¹ 20s
                return cache
            else:
                return {'status': 'offline', 'msg': 'æ¢é’ˆè¶…æ—¶'}

    # 2. API æ¨¡å¼å…œåº•
    if server_conf.get('user'):
        if server_conf.get('_status') == 'online':
             # æ„é€ ç®€å•çŠ¶æ€
             return {'status': 'online', 'msg': 'API Online', 'cpu_usage': 0, 'mem_usage': 0}
    
    return {'status': 'offline', 'msg': 'æœªè¿æ¥'}

async def send_telegram_message(text):
    """å‘é€ TG æ¶ˆæ¯"""
    token = state.ADMIN_CONFIG.get('tg_bot_token')
    chat_id = state.ADMIN_CONFIG.get('tg_chat_id')
    if not token or not chat_id: return
    
    def _post():
        try:
            url = f"https://api.telegram.org/bot{token}/sendMessage"
            requests.post(url, json={"chat_id": chat_id, "text": text, "parse_mode": "Markdown"}, timeout=5)
        except: pass

    await run_in_bg_executor(_post)

async def job_monitor_status():
    """å®šæ—¶ä»»åŠ¡ï¼šæœåŠ¡å™¨çŠ¶æ€ç›‘æ§ä¸æŠ¥è­¦"""
    if not hasattr(state, 'FAILURE_COUNTS'): state.FAILURE_COUNTS = {}
    if not hasattr(state, 'ALERT_CACHE'): state.ALERT_CACHE = {}
    
    sema = asyncio.Semaphore(50)
    FAILURE_THRESHOLD = 3
    current_time = time.strftime("%H:%M:%S", time.localtime())
    
    async def _check(srv):
        if not srv.get('probe_installed', False): return
        
        async with sema:
            url = srv['url']
            name = srv.get('name', 'Unk')
            
            # è·å–çŠ¶æ€
            st = await get_server_status(srv)
            is_online = (st.get('status') == 'online')
            
            # åªæœ‰é…ç½®äº† TG æ‰æŠ¥è­¦
            if not state.ADMIN_CONFIG.get('tg_bot_token'): return

            display_ip = url.split('://')[-1].split(':')[0]

            if is_online:
                state.FAILURE_COUNTS[url] = 0
                if state.ALERT_CACHE.get(url) == 'offline':
                    msg = f"ğŸŸ¢ **æ¢å¤ï¼šæœåŠ¡å™¨å·²ä¸Šçº¿**\nğŸ–¥ï¸ `{name}`\nğŸ”— `{display_ip}`\nğŸ•’ `{current_time}`"
                    await send_telegram_message(msg)
                    state.ALERT_CACHE[url] = 'online'
            else:
                cnt = state.FAILURE_COUNTS.get(url, 0) + 1
                state.FAILURE_COUNTS[url] = cnt
                
                if cnt >= FAILURE_THRESHOLD:
                    if state.ALERT_CACHE.get(url) != 'offline':
                        msg = f"ğŸ”´ **è­¦å‘Šï¼šæœåŠ¡å™¨ç¦»çº¿**\nğŸ–¥ï¸ `{name}`\nğŸ”— `{display_ip}`\nğŸ•’ `{current_time}`"
                        await send_telegram_message(msg)
                        state.ALERT_CACHE[url] = 'offline'

    tasks = [_check(s) for s in state.SERVERS_CACHE]
    if tasks: await asyncio.gather(*tasks)

async def job_sync_all_traffic():
    """å®šæ—¶ä»»åŠ¡ï¼šåŒæ­¥æ‰€æœ‰ API èŠ‚ç‚¹æµé‡"""
    logger.info("ğŸ•’ [æ™ºèƒ½åŒæ­¥] æ£€æŸ¥ API èŠ‚ç‚¹åŒæ­¥...")
    tasks = []
    for s in state.SERVERS_CACHE:
        if s.get('url') and not s.get('probe_installed'):
            tasks.append(fetch_inbounds_safe(s))
    
    if tasks:
        await asyncio.gather(*tasks)
        await save_nodes_cache()
        if state.refresh_dashboard_ui_func: await state.refresh_dashboard_ui_func()

async def job_check_geo_ip():
    """åå°ä»»åŠ¡ï¼šè§£æ IP å½’å±åœ°å¹¶æ›´æ–°å›½æ——"""
    logger.info("ğŸŒ [å®šæ—¶ä»»åŠ¡] IP å½’å±åœ°æ£€æµ‹...")
    changed = False
    for s in state.SERVERS_CACHE:
        if "ğŸ³ï¸" in s.get('name', '') or not any(x in s.get('name', '') for x in ["ğŸ‡¨ğŸ‡³","ğŸ‡ºğŸ‡¸","ğŸ‡­ğŸ‡°","ğŸ‡¯ğŸ‡µ"]):
            try:
                host = s.get('ssh_host') or s.get('url', '').split('://')[-1].split(':')[0]
                if not host: continue
                # è§£æ
                if not re.match(r"^\d+\.\d+\.\d+\.\d+$", host):
                    host = socket.gethostbyname(host)
                
                flag = await run_in_bg_executor(utils.get_flag_from_ip, host)
                if flag and flag != "ğŸ³ï¸" and flag not in s['name']:
                    clean = s['name'].replace("ğŸ³ï¸", "").strip()
                    s['name'] = f"{flag} {clean}"
                    s['group'] = detect_country_group(s['name'])
                    changed = True
            except: pass
            
    if changed:
        await save_servers()
        if state.render_sidebar_content_func: state.render_sidebar_content_func.refresh()

# ================= 4. èŠ‚ç‚¹è·å–ä¸ç®¡ç† =================

async def fetch_inbounds_safe(server_conf, force_refresh=False, sync_name=False):
    """è·å–èŠ‚ç‚¹ç»Ÿä¸€å…¥å£"""
    url = server_conf.get('url')
    
    # è‡ªåŠ¨å‘½åé€»è¾‘
    if sync_name:
        new_name = await generate_smart_name(server_conf)
        if new_name != server_conf.get('name'):
            server_conf['name'] = new_name
            server_conf['group'] = detect_country_group(new_name, server_conf)
            await save_servers()

    # æ¢é’ˆæ¨¡å¼ï¼šç›´æ¥è¯»ç¼“å­˜
    if server_conf.get('probe_installed'):
        return state.NODES_DATA.get(url, [])

    # API æ¨¡å¼
    if not url or not server_conf.get('user'): return []
    
    try:
        mgr = get_manager(server_conf)
        if not mgr: return []
        
        # å…¼å®¹åŒæ­¥/å¼‚æ­¥
        if hasattr(mgr, 'get_inbounds'):
             # æ³¨æ„ï¼šXUI_SSH_Manager æ˜¯åŒæ­¥çš„ï¼ŒXUI_API_Manager ä¹Ÿæ˜¯åŒæ­¥çš„ requests
             # ä½†ä¸ºäº†ä¸é˜»å¡ï¼Œæˆ‘ä»¬ç»Ÿç»Ÿä¸¢è¿›çº¿ç¨‹æ± 
            nodes = await run_in_bg_executor(mgr.get_inbounds)
            if nodes is not None:
                state.NODES_DATA[url] = nodes
                server_conf['_status'] = 'online'
                return nodes
    except Exception as e:
        server_conf['_status'] = 'offline'
    
    return state.NODES_DATA.get(url, [])

def get_manager(server_conf):
    """å·¥å‚å‡½æ•°"""
    # ä¼˜å…ˆ SSH
    if server_conf.get('ssh_host') and server_conf.get('ssh_user'):
        from utils import XUI_SSH_Manager
        return XUI_SSH_Manager(server_conf)
    # å…¶æ¬¡ API
    if server_conf.get('url') and server_conf.get('user'):
        from utils import XUI_API_Manager
        return XUI_API_Manager(server_conf)
    return None

# ================= 5. æ¢é’ˆ/SSH æ“ä½œ =================

async def install_probe_on_server(server_conf):
    """å•å°å®‰è£…æ¢é’ˆ"""
    # è·å–æœ¬æœºIPä½œä¸ºé»˜è®¤å›è°ƒ
    my_ip = "127.0.0.1"
    try:
        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        s.connect(("8.8.8.8", 80)); my_ip = s.getsockname()[0]; s.close()
    except: pass

    base_url = state.ADMIN_CONFIG.get('manager_base_url', f"http://{my_ip}:8080")
    
    script = config.PROBE_INSTALL_SCRIPT \
        .replace("__MANAGER_URL__", base_url) \
        .replace("__TOKEN__", state.ADMIN_CONFIG.get('probe_token', 'default_token')) \
        .replace("__SERVER_URL__", server_conf['url']) \
        .replace("__PING_CT__", state.ADMIN_CONFIG.get('ping_target_ct', '1.1.1.1')) \
        .replace("__PING_CU__", state.ADMIN_CONFIG.get('ping_target_cu', '1.1.1.1')) \
        .replace("__PING_CM__", state.ADMIN_CONFIG.get('ping_target_cm', '1.1.1.1'))

    utils.safe_notify(f"æ­£åœ¨å®‰è£…æ¢é’ˆ: {server_conf['name']}...", "ongoing")
    success, output = await run_in_bg_executor(utils._ssh_exec_wrapper, server_conf, script)
    
    if success:
        server_conf['probe_installed'] = True
        await save_servers()
        utils.safe_notify(f"âœ… {server_conf['name']} æ¢é’ˆå®‰è£…æˆåŠŸ", "positive")
    else:
        utils.safe_notify(f"âŒ å®‰è£…å¤±è´¥: {output}", "negative")

async def batch_install_all_probes():
    """æ‰¹é‡å®‰è£…"""
    utils.safe_notify("å¼€å§‹æ‰¹é‡æ›´æ–°æ¢é’ˆ...", "ongoing")
    tasks = []
    for s in state.SERVERS_CACHE:
        if s.get('ssh_host'):
            tasks.append(install_probe_on_server(s))
    if tasks: await asyncio.gather(*tasks)
    utils.safe_notify("æ‰¹é‡ä»»åŠ¡ç»“æŸ", "positive")

async def force_geoip_naming_task(server_conf):
    """å¼ºåˆ¶ GeoIP å‘½å"""
    await asyncio.sleep(2)
    await generate_smart_name(server_conf) # generate_smart_name å†…éƒ¨ä¼šä¿å­˜

async def smart_detect_ssh_user_task(server_conf):
    """æ™ºèƒ½æ¢æµ‹ SSH ç”¨æˆ·å"""
    candidates = ['root', 'ubuntu', 'debian', 'opc', 'ec2-user', 'admin']
    ip = server_conf.get('ssh_host') or server_conf.get('url').split(':')[1].replace('//','')
    
    logger.info(f"ğŸ•µï¸â€â™‚ï¸ æ­£åœ¨æ¢æµ‹ SSH ç”¨æˆ·: {ip}")
    
    found = None
    for user in candidates:
        server_conf['ssh_user'] = user
        # å°è¯•è¿æ¥
        client, msg = await run_in_bg_executor(utils.get_ssh_client_sync, server_conf)
        if client:
            client.close()
            found = user
            logger.info(f"âœ… æ¢æµ‹æˆåŠŸ: {user}@{ip}")
            break
            
    if found:
        server_conf['ssh_user'] = found
        await save_servers()
        if state.ADMIN_CONFIG.get('probe_enabled', False):
            await install_probe_on_server(server_conf)
    else:
        logger.warning(f"âŒ æ¢æµ‹å¤±è´¥: {ip}")
        # æ¢å¤é»˜è®¤
        server_conf['ssh_user'] = 'root'
        await save_servers()

def record_ping_history(url, pings):
    """è®°å½• Ping å†å²"""
    if url not in state.PING_TREND_CACHE: state.PING_TREND_CACHE[url] = []
    now = time.time()
    rec = {
        'ts': now,
        'time_str': datetime.datetime.fromtimestamp(now).strftime('%H:%M'),
        'ct': pings.get('ç”µä¿¡', -1),
        'cu': pings.get('è”é€š', -1),
        'cm': pings.get('ç§»åŠ¨', -1)
    }
    state.PING_TREND_CACHE[url].append(rec)
    if len(state.PING_TREND_CACHE[url]) > 1440: # 24h
        state.PING_TREND_CACHE[url] = state.PING_TREND_CACHE[url][-1440:]

# ================= 6. å¤‡ä»½/æ¢å¤ (é¡¶å±‚) =================
async def create_backup_zip():
    if not os.path.exists('backup'): os.makedirs('backup')
    name = f"backup/backup_{int(time.time())}.zip"
    return await run_in_bg_executor(_zip_backup_sync, config.DATA_DIR, name)

async def restore_backup_zip(content):
    res = await run_in_bg_executor(_unzip_backup_sync, content, config.DATA_DIR)
    if res: init_data()
    return res

# [logic.py] è¿½åŠ åˆ°æ–‡ä»¶æœ«å°¾

async def fast_resolve_single_server(s):
    """
    åå°å…¨è‡ªåŠ¨ä¿®æ­£æµç¨‹ï¼š
    1. å°è¯•è¿æ¥é¢æ¿ï¼Œè¯»å–ç¬¬ä¸€ä¸ªèŠ‚ç‚¹çš„å¤‡æ³¨å (Smart Name)
    2. å°è¯•æŸ¥è¯¢ IP å½’å±åœ°ï¼Œè·å–å›½æ—— (GeoIP)
    3. è‡ªåŠ¨ç»„åˆåå­— (é˜²æ­¢å›½æ——é‡å¤)
    4. è‡ªåŠ¨å½’ç±»åˆ†ç»„
    """
    await asyncio.sleep(1.5) # ç¨å¾®é”™å³°ï¼Œé¿å…é˜»å¡ UI å“åº”
    
    url = s.get('url', '')
    raw_ip = url.split('://')[-1].split(':')[0]
    logger.info(f"ğŸ” [æ™ºèƒ½ä¿®æ­£] æ­£åœ¨å¤„ç†: {raw_ip} ...")
    
    data_changed = False
    
    try:
        # --- æ­¥éª¤ 1: å°è¯•ä»é¢æ¿è·å–çœŸå®å¤‡æ³¨ ---
        # åªæœ‰å½“åå­—çœ‹èµ·æ¥åƒé»˜è®¤ IP (æˆ–å¸¦ç™½æ——çš„IP) æ—¶ï¼Œæ‰å»é¢æ¿è¯»å–
        current_pure_name = s['name'].replace('ğŸ³ï¸', '').strip()
        
        # å¦‚æœåå­—å°±æ˜¯ IPï¼Œæˆ–è€…æ˜¯ä»¥ Server å¼€å¤´ï¼Œå°è¯•è·å–çœŸå®èŠ‚ç‚¹å
        if current_pure_name == raw_ip or current_pure_name.startswith('Server'):
            try:
                # å¼ºåˆ¶åˆ·æ–°è·å–æœ€æ–°èŠ‚ç‚¹
                nodes = await fetch_inbounds_safe(s, force_refresh=True)
                if nodes and len(nodes) > 0:
                    smart_name = nodes[0].get('remark', '').strip()
                    # å¦‚æœè·å–åˆ°äº†æœ‰æ•ˆåå­—
                    if smart_name and smart_name != raw_ip:
                        s['name'] = smart_name
                        data_changed = True
                        logger.info(f"ğŸ·ï¸ [è·å–å¤‡æ³¨] æˆåŠŸ: {smart_name}")
            except Exception as e:
                logger.warning(f"âš ï¸ [è·å–å¤‡æ³¨] å¤±è´¥: {e}")

        # --- æ­¥éª¤ 2: æŸ¥ IP å½’å±åœ°å¹¶ä¿®æ­£å›½æ——/åˆ†ç»„ ---
        # è§£æçœŸå® Host (ä¼˜å…ˆ SSH Hostï¼Œå…¶æ¬¡ URL)
        host = s.get('ssh_host') or raw_ip
        
        # å¦‚æœæ˜¯åŸŸåï¼Œå°è¯•è§£æä¸º IP
        import socket
        try:
            if not re.match(r"^\d+\.\d+\.\d+\.\d+$", host):
                host = await run_in_bg_executor(socket.gethostbyname, host)
        except: pass

        # æŸ¥è¯¢ GeoIP
        flag = await run_in_bg_executor(utils.get_flag_from_ip, host)
        
        if flag and flag != "ğŸ³ï¸":
            # è·å–æ­£ç¡®çš„å›½æ——
            s['lat'] = None # é‡ç½®åæ ‡è®©åœ°å›¾é‡æ–°è·å–
            s['lon'] = None
            
            # âœ¨âœ¨âœ¨ [æ ¸å¿ƒä¿®å¤] å›½æ——é˜²é‡å¤é€»è¾‘ âœ¨âœ¨âœ¨
            # 1. å…ˆæŠŠç™½æ——å»æ‰ï¼Œæ‹¿åˆ°å¹²å‡€çš„åå­—
            temp_name = s['name'].replace('ğŸ³ï¸', '').strip()
            
            # 2. æ£€æŸ¥åå­—é‡Œæ˜¯å¦å·²ç»åŒ…å«äº†æ­£ç¡®çš„å›½æ——
            if flag in temp_name:
                # å¦‚æœåŒ…å«äº†ï¼Œåªæ›´æ–°å»æ‰ç™½æ——åçš„æ ·å­
                if s['name'] != temp_name:
                    s['name'] = temp_name
                    data_changed = True
            else:
                # 3. å¦‚æœæ²¡åŒ…å«ï¼ŒåŠ åˆ°æœ€å‰é¢
                s['name'] = f"{flag} {temp_name}"
                data_changed = True

            # --- æ­¥éª¤ 3: å¼ºåˆ¶è‡ªåŠ¨åˆ†ç»„ ---
            # å°è¯•æ ¹æ®æ–°åå­—è‡ªåŠ¨åˆ¤æ–­åˆ†ç»„
            target_group = detect_country_group(s['name'], s)
            
            # åªæœ‰å½“å½“å‰åˆ†ç»„æ˜¯é»˜è®¤åˆ†ç»„æ—¶ï¼Œæ‰è‡ªåŠ¨å½’ç±»
            if s.get('group') in ['é»˜è®¤åˆ†ç»„', 'è‡ªåŠ¨æ³¨å†Œ', 'æœªåˆ†ç»„'] and target_group != 'ğŸ³ï¸ å…¶ä»–åœ°åŒº':
                s['group'] = target_group
                data_changed = True
        else:
            # æ²¡æŸ¥åˆ° IP ä¿¡æ¯
            pass

        # --- æ­¥éª¤ 4: ä¿å­˜å˜æ›´ ---
        if data_changed:
            await save_servers()
            # åˆ·æ–° UI
            if state.refresh_dashboard_ui_func: await state.refresh_dashboard_ui_func()
            if state.render_sidebar_content_func: state.render_sidebar_content_func.refresh()
            logger.info(f"âœ… [æ™ºèƒ½ä¿®æ­£] å®Œæ¯•: {s['name']} -> [{s['group']}]")
            
    except Exception as e:
        logger.error(f"âŒ [æ™ºèƒ½ä¿®æ­£] ä¸¥é‡é”™è¯¯: {e}")
