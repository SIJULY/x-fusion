# logic.py
import json
import os
import asyncio
import time
import logging
import datetime
import zipfile
import io
import shutil
from concurrent.futures import ThreadPoolExecutor

import config
import state
import utils

logger = logging.getLogger("XUI_Manager")


# ================= 0. é¡¶å±‚åŒæ­¥å‡½æ•° (ç”¨äºå¤šè¿›ç¨‹è°ƒç”¨) =================
# å¿…é¡»å®šä¹‰åœ¨æœ€å¤–å±‚ï¼Œå¦åˆ™ ProcessPoolExecutor æ— æ³• Pickle (æŠ¥é”™)

def _save_json_sync(file_path, data):
    """åŒæ­¥å†™å…¥ JSON æ–‡ä»¶"""
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    parent = os.path.dirname(file_path)
    if not os.path.exists(parent):
        os.makedirs(parent)

    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=2, ensure_ascii=False)
    return True


def _save_nodes_sync(file_path, data):
    """åŒæ­¥å†™å…¥èŠ‚ç‚¹ç¼“å­˜ (ç´§å‡‘æ ¼å¼)"""
    parent = os.path.dirname(file_path)
    if not os.path.exists(parent):
        os.makedirs(parent)

    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False)
    return True


def _zip_backup_sync(data_dir, zip_filename):
    """åŒæ­¥åˆ›å»ºå‹ç¼©åŒ…"""
    with zipfile.ZipFile(zip_filename, 'w') as zf:
        if os.path.exists(data_dir):
            for root, _, files in os.walk(data_dir):
                for file in files:
                    file_path = os.path.join(root, file)
                    arcname = os.path.relpath(file_path, data_dir)
                    zf.write(file_path, arcname)
    return zip_filename


def _unzip_backup_sync(content_bytes, data_dir):
    """åŒæ­¥è§£å‹æ¢å¤"""
    try:
        with zipfile.ZipFile(io.BytesIO(content_bytes)) as zf:
            # æ¸…ç©º data ç›®å½•
            if os.path.exists(data_dir):
                shutil.rmtree(data_dir)
            os.makedirs(data_dir)
            zf.extractall(data_dir)
        return True
    except:
        return False


# ================= 1. æ•°æ®åˆå§‹åŒ–ä¸ä¿å­˜ =================

def init_data():
    """åˆå§‹åŒ–æ•°æ®ç›®å½•å’ŒåŠ è½½ç¼“å­˜"""
    if not os.path.exists(config.DATA_DIR):
        os.makedirs(config.DATA_DIR)
        logger.info(f"åˆ›å»ºæ•°æ®ç›®å½•: {config.DATA_DIR}")

    # 1. åŠ è½½æœåŠ¡å™¨åˆ—è¡¨
    if os.path.exists(config.CONFIG_FILE):
        try:
            with open(config.CONFIG_FILE, 'r', encoding='utf-8') as f:
                state.SERVERS_CACHE = json.load(f)
            logger.info(f"âœ… åŠ è½½æœåŠ¡å™¨: {len(state.SERVERS_CACHE)} å°")
        except Exception as e:
            logger.error(f"åŠ è½½æœåŠ¡å™¨é…ç½®å¤±è´¥: {e}")
            state.SERVERS_CACHE = []
    else:
        logger.warning(f"âš ï¸ æœªæ‰¾åˆ°æœåŠ¡å™¨é…ç½®æ–‡ä»¶: {config.CONFIG_FILE}")

    # 2. åŠ è½½èŠ‚ç‚¹ç¼“å­˜ (é˜²æ­¢é‡å¯åæµé‡æ•°æ®ä¸¢å¤±)
    if os.path.exists(config.NODES_CACHE_FILE):
        try:
            with open(config.NODES_CACHE_FILE, 'r', encoding='utf-8') as f:
                state.NODES_DATA = json.load(f)
            # ç»Ÿè®¡èŠ‚ç‚¹æ€»æ•°
            total_nodes = sum(len(nodes) for nodes in state.NODES_DATA.values())
            logger.info(f"âœ… åŠ è½½ç¼“å­˜èŠ‚ç‚¹: {total_nodes} ä¸ª")
        except Exception as e:
            logger.error(f"åŠ è½½èŠ‚ç‚¹ç¼“å­˜å¤±è´¥: {e}")

    # 3. åŠ è½½è®¢é˜…
    if os.path.exists(config.SUBS_FILE):
        try:
            with open(config.SUBS_FILE, 'r', encoding='utf-8') as f:
                state.SUBS_CACHE = json.load(f)
            logger.info(f"âœ… åŠ è½½è®¢é˜…: {len(state.SUBS_CACHE)} ä¸ª")
        except:
            pass

    # 4. åŠ è½½ç®¡ç†å‘˜é…ç½®
    if os.path.exists(config.ADMIN_CONFIG_FILE):
        try:
            with open(config.ADMIN_CONFIG_FILE, 'r', encoding='utf-8') as f:
                saved_conf = json.load(f)
                state.ADMIN_CONFIG.update(saved_conf)
        except:
            pass


async def save_servers():
    """å¼‚æ­¥ä¿å­˜æœåŠ¡å™¨åˆ—è¡¨"""
    try:
        # å°†æ•°æ®ä¼ ç»™é¡¶å±‚å‡½æ•°ï¼Œé¿å…é—­åŒ… Pickle é—®é¢˜
        await run_in_bg_executor(_save_json_sync, config.CONFIG_FILE, state.SERVERS_CACHE)
    except Exception as e:
        logger.error(f"ä¿å­˜æœåŠ¡å™¨å¤±è´¥: {e}")


async def save_subs():
    """å¼‚æ­¥ä¿å­˜è®¢é˜…"""
    try:
        await run_in_bg_executor(_save_json_sync, config.SUBS_FILE, state.SUBS_CACHE)
    except Exception as e:
        logger.error(f"ä¿å­˜è®¢é˜…å¤±è´¥: {e}")


async def save_nodes_cache():
    """å¼‚æ­¥ä¿å­˜èŠ‚ç‚¹æ•°æ®ç¼“å­˜"""
    try:
        await run_in_bg_executor(_save_nodes_sync, config.NODES_CACHE_FILE, state.NODES_DATA)
    except Exception as e:
        logger.error(f"ä¿å­˜èŠ‚ç‚¹ç¼“å­˜å¤±è´¥: {e}")


async def save_admin_config():
    """ä¿å­˜ç®¡ç†å‘˜é…ç½®"""
    try:
        await run_in_bg_executor(_save_json_sync, config.ADMIN_CONFIG_FILE, state.ADMIN_CONFIG)
    except:
        pass


# ================= 2. æ ¸å¿ƒä¸šåŠ¡é€»è¾‘ =================

def calculate_dashboard_data():
    """è®¡ç®—ä»ªè¡¨ç›˜æ‰€éœ€çš„å„ç±»ç»Ÿè®¡æ•°æ®"""
    try:
        # 1. æœåŠ¡å™¨åœ¨çº¿ç»Ÿè®¡
        total_servers = len(state.SERVERS_CACHE)
        online_servers = len([s for s in state.SERVERS_CACHE if s.get('_status') == 'online'])

        # 2. èŠ‚ç‚¹ä¸æµé‡ç»Ÿè®¡
        total_nodes = 0
        total_up = 0
        total_down = 0

        # æµé‡æ’è¡Œæ•°æ®
        traffic_rank = []

        for srv in state.SERVERS_CACHE:
            url = srv.get('url')
            # è·å–è¯¥æœåŠ¡å™¨ä¸‹çš„æ‰€æœ‰èŠ‚ç‚¹ï¼ˆAPIè·å–çš„ + è‡ªå®šä¹‰çš„ï¼‰
            api_nodes = state.NODES_DATA.get(url, []) or []
            custom_nodes = srv.get('custom_nodes', []) or []

            srv_up = 0
            srv_down = 0

            # ç»Ÿè®¡ API èŠ‚ç‚¹
            for n in api_nodes:
                total_nodes += 1
                u = n.get('up', 0)
                d = n.get('down', 0)
                srv_up += u
                srv_down += d

            # ç»Ÿè®¡è‡ªå®šä¹‰èŠ‚ç‚¹ (é€šå¸¸æ— æµé‡æ•°æ®ï¼Œä½†åœ¨åˆ—è¡¨ä¸­è®¡æ•°)
            total_nodes += len(custom_nodes)

            total_up += srv_up
            total_down += srv_down

            # åŠ å…¥æ’è¡Œ (ä»…å½“æœ‰æµé‡æ—¶)
            total_traffic = srv_up + srv_down
            if total_traffic > 0:
                traffic_rank.append({
                    'name': srv.get('name', 'Unknown'),
                    'value': round(total_traffic / 1024 / 1024 / 1024, 2)  # GB
                })

        # 3. æ’åºå¹¶æˆªå–å‰ 10 å
        traffic_rank.sort(key=lambda x: x['value'], reverse=True)
        top_10 = traffic_rank[:10]

        bar_chart_data = {
            'names': [x['name'] for x in top_10],
            'values': [x['value'] for x in top_10]
        }

        # 4. åŒºåŸŸåˆ†å¸ƒç»Ÿè®¡ (é¥¼å›¾)
        from collections import Counter
        region_cnt = Counter()
        for s in state.SERVERS_CACHE:
            # å°è¯•è·å–å›½æ——æˆ–ç»„å
            group = detect_country_group(s.get('name', ''), s)
            region_cnt[group] += 1

        pie_data = []
        for k, v in region_cnt.most_common(8):
            pie_data.append({'name': k, 'value': v})

        # 5. æ ¼å¼åŒ–æ€»æµé‡
        total_traffic_bytes = total_up + total_down
        formatted_traffic = utils.format_bytes(total_traffic_bytes)

        return {
            "servers": f"{online_servers} / {total_servers}",
            "nodes": str(total_nodes),
            "traffic": formatted_traffic,
            "subs": str(len(state.SUBS_CACHE)),
            "bar_chart": bar_chart_data,
            "pie_chart": pie_data
        }
    except Exception as e:
        logger.error(f"ä»ªè¡¨ç›˜æ•°æ®è®¡ç®—é”™è¯¯: {e}")
        return None


def detect_country_group(name, server_obj=None):
    """æ ¹æ®æœåŠ¡å™¨åç§°æˆ–é…ç½®è‡ªåŠ¨åˆ¤æ–­åŒºåŸŸ"""
    # 1. ä¼˜å…ˆæ£€æŸ¥ server_obj ä¸­æ˜¯å¦å·²æœ‰æ‰‹åŠ¨åˆ†ç»„
    if server_obj and server_obj.get('group') and server_obj['group'] not in ['é»˜è®¤åˆ†ç»„', 'è‡ªåŠ¨æ³¨å†Œ', 'æœªåˆ†ç»„']:
        return server_obj['group']

    # 2. æ£€æŸ¥åç§°ä¸­çš„å›½æ——
    for flag, country in config.AUTO_COUNTRY_MAP.items():
        if flag in name:
            return country

    # 3. æ£€æŸ¥åç§°ä¸­çš„å…³é”®è¯ (ä¸åŒºåˆ†å¤§å°å†™)
    name_lower = name.lower()
    for key, country in config.AUTO_COUNTRY_MAP.items():
        if len(key) > 2 and key.lower() in name_lower:  # å¿½ç•¥é•¿åº¦ä¸º2çš„ç®€å†™ï¼Œé˜²æ­¢è¯¯åˆ¤
            return country

    return "ğŸ³ï¸ å…¶ä»–åœ°åŒº"


# ================= 3. ä»»åŠ¡è°ƒåº¦ä¸åå°æ‰§è¡Œ =================

async def run_in_bg_executor(func, *args):
    """åœ¨åå°çº¿ç¨‹æ± ä¸­è¿è¡ŒåŒæ­¥å‡½æ•°"""
    loop = asyncio.get_running_loop()
    if state.PROCESS_POOL is None:
        # å¦‚æœæ± æœªåˆå§‹åŒ–ï¼Œä¸´æ—¶ä½¿ç”¨é»˜è®¤æ‰§è¡Œå™¨
        return await loop.run_in_executor(None, func, *args)
    return await loop.run_in_executor(state.PROCESS_POOL, func, *args)


async def job_sync_all_traffic():
    """å®šæ—¶ä»»åŠ¡ï¼šåŒæ­¥æ‰€æœ‰ API èŠ‚ç‚¹æµé‡"""
    logger.info("ğŸ•’ [æ™ºèƒ½åŒæ­¥] æ£€æŸ¥åŒæ­¥ä»»åŠ¡è¿›åº¦...")

    tasks = []
    for s in state.SERVERS_CACHE:
        # ä»…åŒæ­¥é…ç½®äº† API çš„æœºå™¨ï¼Œä¸”æœªå®‰è£…æ¢é’ˆçš„ (æ¢é’ˆä¼šä¸»åŠ¨æ¨)
        if s.get('url') and not s.get('probe_installed'):
            tasks.append(fetch_inbounds_safe(s))

    if tasks:
        await asyncio.gather(*tasks)
        logger.info(f"âœ… [æ™ºèƒ½åŒæ­¥] å®Œæˆ {len(tasks)} ä¸ª API èŠ‚ç‚¹çš„åŒæ­¥")
        # ä¿å­˜ä¸€æ¬¡ç¼“å­˜
        await save_nodes_cache()
        # åˆ·æ–° UI
        if state.refresh_dashboard_ui_func: await state.refresh_dashboard_ui_func()


async def job_monitor_status():
    """å®šæ—¶ä»»åŠ¡ï¼šç®€å•çš„çŠ¶æ€æ£€æŸ¥"""
    # è¿™é‡Œå¯ä»¥æ‰©å±•æ›´å¤æ‚çš„ TCP Pingï¼Œç›®å‰ä¸»è¦ä¾èµ–æ¢é’ˆæ¨é€æ›´æ–°çŠ¶æ€
    pass


async def job_check_geo_ip():
    """åå°ä»»åŠ¡ï¼šè§£æ IP å½’å±åœ°å¹¶æ›´æ–°å›½æ——"""
    import socket
    logger.info("ğŸŒ [å®šæ—¶ä»»åŠ¡] å¼€å§‹å…¨é‡ IP å½’å±åœ°æ£€æµ‹ä¸åç§°ä¿®æ­£...")

    changed = False
    for s in state.SERVERS_CACHE:
        try:
            # å¦‚æœåå­—é‡Œæ²¡æœ‰å›½æ——ï¼Œä¸”ä¸æ˜¯è‡ªå®šä¹‰åˆ†ç»„
            if "ğŸ³ï¸" in s.get('name', '') or not any(c in s.get('name', '') for c in "ğŸ‡¨ğŸ‡³ğŸ‡ºğŸ‡¸ğŸ‡­ğŸ‡°ğŸ‡¯ğŸ‡µğŸ‡°ğŸ‡·ğŸ‡¸ğŸ‡¬"):
                # è·å– Host
                host = s.get('ssh_host') or s.get('url', '').replace('http://', '').replace('https://', '').split(':')[
                    0]
                if not host: continue

                # è§£æ IP
                try:
                    ip = socket.gethostbyname(host)
                except:
                    continue

                # è·å– GeoInfo
                flag = await run_in_bg_executor(utils.get_flag_from_ip, ip)

                if flag and flag not in s['name']:
                    # ç§»é™¤æ—§çš„ç™½æ——
                    clean_name = s['name'].replace("ğŸ³ï¸", "").strip()
                    s['name'] = f"{flag} {clean_name}"
                    s['group'] = detect_country_group(s['name'])
                    changed = True
        except:
            pass

    if changed:
        await save_servers()
        logger.info("âœ… åç§°æ£€æŸ¥å®Œæ¯•ï¼Œå·²ä¿®æ­£éƒ¨åˆ†æœåŠ¡å™¨å›½æ——")
    else:
        logger.info("âœ… åç§°æ£€æŸ¥å®Œæ¯•ï¼Œæ— éœ€ä¿®æ­£")


# ================= 4. èŠ‚ç‚¹è·å–é€»è¾‘ =================

# [logic.py] è¯·æ›¿æ¢åŸæœ‰çš„ fetch_inbounds_safe å‡½æ•°
async def fetch_inbounds_safe(server_conf, force_refresh=False, sync_name=False):
    """
    è·å–èŠ‚ç‚¹çš„ç»Ÿä¸€å…¥å£ã€‚
    1. å¦‚æœæ˜¯ Root æ¨¡å¼ï¼Œä¼˜å…ˆå°è¯• SSH è·å–
    2. å¦‚æœæ˜¯ API æ¨¡å¼ï¼Œå°è¯• HTTP è·å–
    3. å¤±è´¥åˆ™è¿”å›ç¼“å­˜
    4. sync_name=True æ—¶ï¼Œä¼šè§¦å‘è‡ªåŠ¨å‘½åå’Œè‡ªåŠ¨åˆ†ç»„
    """
    url = server_conf.get('url')

    # --- è‡ªåŠ¨å‘½åä¸åˆ†ç»„é€»è¾‘ (ä¿®å¤ç‚¹) ---
    if sync_name:
        try:
            # 1. è§£æçœŸå® IP
            host = server_conf.get('ssh_host')
            if not host and url:
                host = url.replace('http://', '').replace('https://', '').split(':')[0]

            if host:
                # 2. è·å–å›½æ——
                import socket
                try:
                    # å¦‚æœæ˜¯åŸŸååˆ™è§£æ
                    if not any(char.isdigit() for char in host):
                        host = socket.gethostbyname(host)
                except:
                    pass

                flag = await run_in_bg_executor(utils.get_flag_from_ip, host)

                # 3. æ›´æ–°åç§° (ä¿ç•™åŸæœ‰å¤‡æ³¨ï¼Œå¢åŠ å›½æ——)
                old_name = server_conf.get('name', 'Server')
                # å¦‚æœåå­—é‡Œè¿˜æ²¡å›½æ——ï¼ŒåŠ ä¸Šå»
                if flag != "ğŸ³ï¸" and flag not in old_name:
                    clean_name = old_name.replace("ğŸ³ï¸", "").strip()
                    # å¦‚æœåŸåæ˜¯ IP æˆ– URLï¼Œç›´æ¥ç”¨ "å›½æ—— å›½å®¶" æ ¼å¼
                    if clean_name == host or clean_name == url:
                        # å°è¯•è·å–å›½å®¶å
                        pass  # ç®€å•å¤„ç†ï¼Œç›´æ¥åŠ å›½æ——
                    server_conf['name'] = f"{flag} {clean_name}"

                # 4. è‡ªåŠ¨æ›´æ–°åˆ†ç»„
                new_group = detect_country_group(server_conf['name'], server_conf)
                if new_group != 'ğŸ³ï¸ å…¶ä»–åœ°åŒº':
                    server_conf['group'] = new_group

                await save_servers()
        except Exception as e:
            logger.error(f"è‡ªåŠ¨åŒæ­¥åç§°å¤±è´¥: {e}")

    # ç­–ç•¥ A: æ¢é’ˆ/SSH æ¨¡å¼ (é€šå¸¸ä¸ä¸»åŠ¨æ‹‰å–ï¼Œé™¤é force_refresh)
    if server_conf.get('probe_installed'):
        # ç›´æ¥è¿”å›ç¼“å­˜ (æ¢é’ˆæ•°æ®å·²é€šè¿‡ push æ¥å£å†™å…¥ç¼“å­˜)
        return state.NODES_DATA.get(url, [])

    # ç­–ç•¥ B: API æ¨¡å¼
    if not url or not server_conf.get('user'):
        return []

    try:
        mgr = get_manager(server_conf)
        if not mgr: return []

        # å¼‚æ­¥è°ƒç”¨è·å–
        if hasattr(mgr, 'get_inbounds'):
            # å…¼å®¹åŒæ­¥å’Œå¼‚æ­¥
            if asyncio.iscoroutinefunction(mgr.get_inbounds):
                nodes = await mgr.get_inbounds()
            else:
                nodes = await run_in_bg_executor(mgr.get_inbounds)

            if nodes:
                state.NODES_DATA[url] = nodes
                server_conf['_status'] = 'online'
                return nodes
    except Exception as e:
        logger.warning(f"è·å–èŠ‚ç‚¹å¤±è´¥ [{server_conf.get('name')}]: {e}")
        server_conf['_status'] = 'offline'

    return state.NODES_DATA.get(url, [])


def get_manager(server_conf):
    """å·¥å‚å‡½æ•°ï¼šæ ¹æ®é…ç½®è¿”å›å¯¹åº”çš„ç®¡ç†å™¨å®ä¾‹ (XUI_API æˆ– XUI_SSH)"""
    # 1. ä¼˜å…ˆ SSH
    if server_conf.get('ssh_host') and server_conf.get('ssh_user'):
        from utils import XUI_SSH_Manager  # é¿å…å¾ªç¯å¼•ç”¨ï¼Œå±€éƒ¨å¯¼å…¥
        return XUI_SSH_Manager(server_conf)

    # 2. å…¶æ¬¡ API
    if server_conf.get('url') and server_conf.get('user'):
        from utils import XUI_API_Manager
        return XUI_API_Manager(server_conf)

    return None


# ================= 5. æ¢é’ˆæ‰¹é‡å®‰è£…ä¸è¾…åŠ© =================

async def batch_install_all_probes():
    """ä¸ºæ‰€æœ‰é…ç½®äº† SSH çš„æœåŠ¡å™¨å®‰è£…/æ›´æ–°æ¢é’ˆ"""
    from config import PROBE_INSTALL_SCRIPT
    success_count = 0

    # è·å–æœ¬æœº IP
    my_ip = "127.0.0.1"
    try:
        import socket
        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        s.connect(("8.8.8.8", 80))
        my_ip = s.getsockname()[0]
        s.close()
    except:
        pass

    # è·å–ç«¯å£
    base_url = state.ADMIN_CONFIG.get('manager_base_url', f"http://{my_ip}:8080")

    final_script = PROBE_INSTALL_SCRIPT.replace("__MANAGER_URL__", base_url) \
        .replace("__TOKEN__", state.ADMIN_CONFIG.get('probe_token', 'default_token')) \
        .replace("__PING_CT__", state.ADMIN_CONFIG.get('ping_target_ct', '1.1.1.1')) \
        .replace("__PING_CU__", state.ADMIN_CONFIG.get('ping_target_cu', '1.1.1.1')) \
        .replace("__PING_CM__", state.ADMIN_CONFIG.get('ping_target_cm', '1.1.1.1'))

    for s in state.SERVERS_CACHE:
        if s.get('ssh_host'):
            try:
                utils.safe_notify(f"æ­£åœ¨å‘ {s['name']} æ¨é€æ¢é’ˆ...", "ongoing")
                ok, _ = await run_in_bg_executor(utils._ssh_exec_wrapper, s, final_script)
                if ok:
                    success_count += 1
                    s['probe_installed'] = True
            except:
                pass

    await save_servers()
    utils.safe_notify(f"æ‰¹é‡æ›´æ–°å®Œæˆ: æˆåŠŸ {success_count} å°", "positive")


async def force_geoip_naming_task(server_conf):
    """æ³¨å†ŒæˆåŠŸåï¼Œå¼ºåˆ¶æ‰§è¡Œä¸€æ¬¡ GeoIP å‘½å"""
    await asyncio.sleep(2)  # ç­‰å¾…ç½‘ç»œç¨³å®š
    try:
        host = server_conf.get('ssh_host') or server_conf.get('url', '').split('://')[-1].split(':')[0]
        flag = await run_in_bg_executor(utils.get_flag_from_ip, host)
        if flag:
            server_conf['name'] = f"{flag} {server_conf.get('name', '').replace('ğŸ³ï¸', '').strip()}"
            await save_servers()
    except:
        pass


# [logic.py] æ›¿æ¢åŸæœ‰çš„ pass
async def smart_detect_ssh_user_task(server_conf):
    """è‡ªåŠ¨æ¢æµ‹ SSH ç”¨æˆ·å"""
    candidates = ['ubuntu', 'root', 'debian', 'opc', 'ec2-user', 'admin']
    ip = server_conf['url'].split('://')[-1].split(':')[0]
    
    logger.info(f"ğŸ•µï¸â€â™‚ï¸ [æ™ºèƒ½æ¢æµ‹] å¼€å§‹æ¢æµ‹ {server_conf['name']} ({ip}) ...")
    
    found_user = None
    for user in candidates:
        server_conf['ssh_user'] = user
        # å°è¯•è¿æ¥
        client, msg = await run_in_bg_executor(utils.get_ssh_client_sync, server_conf)
        if client:
            client.close()
            found_user = user
            logger.info(f"âœ… [æ™ºèƒ½æ¢æµ‹] æˆåŠŸåŒ¹é…ç”¨æˆ·å: {user}")
            break
            
    if found_user:
        server_conf['ssh_user'] = found_user
        await save_servers()
        # è§¦å‘æ¢é’ˆå®‰è£…
        if state.ADMIN_CONFIG.get('probe_enabled', False):
            await asyncio.sleep(2)
            await batch_install_all_probes() # è¿™é‡Œå¯èƒ½ä¼šé‡å¤å®‰è£…æ‰€æœ‰ï¼Œå»ºè®®ä¼˜åŒ–ä¸ºåªå®‰è£…å•å°
            # æˆ–è€…è°ƒç”¨: await install_probe_on_server(server_conf) # éœ€è¦å°† install_probe_on_server ç§»åˆ° logic.py
    else:
        logger.error(f"âŒ [æ™ºèƒ½æ¢æµ‹] {server_conf['name']} å¤±è´¥")


def record_ping_history(url, pings):
    """è®°å½• Ping å†å² (ä¿ç•™æœ€è¿‘24å°æ—¶)"""
    if url not in state.PING_TREND_CACHE:
        state.PING_TREND_CACHE[url] = []

    now = time.time()
    record = {
        'ts': now,
        'time_str': datetime.datetime.fromtimestamp(now).strftime('%H:%M'),
        'ct': pings.get('ç”µä¿¡', -1),
        'cu': pings.get('è”é€š', -1),
        'cm': pings.get('ç§»åŠ¨', -1)
    }
    state.PING_TREND_CACHE[url].append(record)

    # æ¸…ç†è¿‡æœŸæ•°æ® (ä¿ç•™ 1440 ä¸ªç‚¹ = 24å°æ—¶ * 60åˆ†)
    if len(state.PING_TREND_CACHE[url]) > 1440:
        state.PING_TREND_CACHE[url] = state.PING_TREND_CACHE[url][-1440:]


# ================= 6. å¤‡ä»½/æ¢å¤é€»è¾‘ (é¡¶å±‚è°ƒç”¨) =================

async def create_backup_zip():
    if not os.path.exists('backup'): os.makedirs('backup')
    zip_filename = f"backup/backup_{int(time.time())}.zip"

    # è°ƒç”¨é¡¶å±‚åŒæ­¥å‡½æ•°
    return await run_in_bg_executor(_zip_backup_sync, config.DATA_DIR, zip_filename)


async def restore_backup_zip(content_bytes):
    # è°ƒç”¨é¡¶å±‚åŒæ­¥å‡½æ•°
    res = await run_in_bg_executor(_unzip_backup_sync, content_bytes, config.DATA_DIR)
    if res:
        init_data()  # é‡æ–°åŠ è½½å†…å­˜
    return res

# [logic.py] æ›¿æ¢åŸæœ‰çš„ pass
async def job_monitor_status():
    """å®šæ—¶ä»»åŠ¡ï¼šæœåŠ¡å™¨çŠ¶æ€ç›‘æ§ä¸æŠ¥è­¦"""
    # é™åˆ¶å¹¶å‘
    sema = asyncio.Semaphore(50)
    FAILURE_THRESHOLD = 3
    current_time = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())
    
    # å®šä¹‰æŠ¥è­¦ç¼“å­˜ (éœ€è¦åœ¨ state.py ä¸­æ·»åŠ  ALERT_CACHE = {} å’Œ FAILURE_COUNTS = {})
    if not hasattr(state, 'ALERT_CACHE'): state.ALERT_CACHE = {}
    if not hasattr(state, 'FAILURE_COUNTS'): state.FAILURE_COUNTS = {}

    async def _check_single_server(srv):
        # ä»…ç›‘æ§å·²å®‰è£…æ¢é’ˆçš„æœºå™¨
        if not srv.get('probe_installed', False): return

        async with sema:
            await asyncio.sleep(0.01)
            url = srv['url']
            name = srv.get('name', 'Unknown')
            
            # è·å–çŠ¶æ€
            res = await get_server_status(srv)
            is_online = (isinstance(res, dict) and res.get('status') == 'online')

            # TG æŠ¥è­¦é€»è¾‘
            if not state.ADMIN_CONFIG.get('tg_bot_token'): return

            display_ip = url.split('://')[-1].split(':')[0]

            if is_online:
                state.FAILURE_COUNTS[url] = 0
                # å‘é€æ¢å¤é€šçŸ¥
                if state.ALERT_CACHE.get(url) == 'offline':
                    msg = f"ğŸŸ¢ **æ¢å¤**\nğŸ–¥ï¸ `{name}`\nğŸ”— `{display_ip}`\nğŸ•’ `{current_time}`"
                    asyncio.create_task(send_telegram_message(msg))
                    state.ALERT_CACHE[url] = 'online'
            else:
                count = state.FAILURE_COUNTS.get(url, 0) + 1
                state.FAILURE_COUNTS[url] = count
                
                if count >= FAILURE_THRESHOLD:
                    if state.ALERT_CACHE.get(url) != 'offline':
                        msg = f"ğŸ”´ **ç¦»çº¿æŠ¥è­¦**\nğŸ–¥ï¸ `{name}`\nğŸ”— `{display_ip}`\nğŸ•’ `{current_time}`"
                        asyncio.create_task(send_telegram_message(msg))
                        state.ALERT_CACHE[url] = 'offline'

    tasks = [_check_single_server(s) for s in state.SERVERS_CACHE]
    if tasks: await asyncio.gather(*tasks)

# è¾…åŠ©å‡½æ•°ï¼šå‘é€ TG (æ”¾åœ¨ logic.py æˆ– utils.py)
async def send_telegram_message(text):
    token = state.ADMIN_CONFIG.get('tg_bot_token')
    chat_id = state.ADMIN_CONFIG.get('tg_chat_id')
    if not token or not chat_id: return
    try:
        url = f"https://api.telegram.org/bot{token}/sendMessage"
        await run_in_bg_executor(requests.post, url, {"chat_id": chat_id, "text": text, "parse_mode": "Markdown"}, timeout=5)
    except: pass

